{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dshra\\tugasakhir\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(480, 911, 1035, 356)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = face_recognition.load_image_file(\"./public/photo_2023-10-29_12-39-45.jpg\")\n",
    "image = face_recognition.face_locations(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = tf.keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet')\n",
    "modelR = tf.keras.Model(inputs=resnet50.input, outputs=resnet50.get_layer('conv4_block5_out').output)\n",
    "\n",
    "xception = tf.keras.applications.xception.Xception(include_top=False, weights='imagenet')\n",
    "modelX = tf.keras.Model(inputs=xception.input, outputs=xception.get_layer('conv2d_2').output)\n",
    "\n",
    "vgg19 = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet')\n",
    "modelV = tf.keras.Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_R = \"./resnet/my_capsule_network\"  \n",
    "checkpoint_path_X = \"./xception/my_capsule_network\"  \n",
    "checkpoint_path_V = \"./vgg/my_capsule_network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    # Convert the image to a NumPy array\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    # Define augmentation sequence\n",
    "    augmenter = iaa.Sequential([\n",
    "        iaa.AdditiveGaussianNoise(scale=(0, 0.05 * 255)), \n",
    "    ])\n",
    "\n",
    "    # Apply the augmentation to the image\n",
    "    img_array = augmenter.augment_image(img_array)\n",
    "\n",
    "    # Resize the augmented image to a specific size (e.g., 224x224 pixels)\n",
    "    img_array = cv2.resize(img_array, (224, 224))\n",
    "\n",
    "    # Perform any other preprocessing steps like normalization (if needed)\n",
    "\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dshra\\AppData\\Local\\Temp\\ipykernel_31628\\2583071831.py:24: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv1 = tf.compat.v1.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
      "C:\\Users\\dshra\\AppData\\Local\\Temp\\ipykernel_31628\\2583071831.py:25: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv2 = tf.compat.v1.layers.conv2d(conv1, name=\"conv2\", **conv2_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[328350, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dshra\\AppData\\Local\\Temp\\ipykernel_31628\\2583071831.py:187: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  hidden1 = tf.compat.v1.layers.dense(decoder_input, n_hidden1,\n",
      "C:\\Users\\dshra\\AppData\\Local\\Temp\\ipykernel_31628\\2583071831.py:190: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  hidden2 = tf.compat.v1.layers.dense(hidden1, n_hidden2,\n",
      "C:\\Users\\dshra\\AppData\\Local\\Temp\\ipykernel_31628\\2583071831.py:193: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  decoder_output = tf.compat.v1.layers.dense(hidden2, n_output,\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "X = tf.compat.v1.placeholder(shape=[None, 14, 14, 1], dtype=tf.float32, name=\"X\") #14, 14\n",
    "\n",
    "caps1_n_maps = 8 #ku ubah\n",
    "caps1_n_caps = caps1_n_maps * 10 * 10\n",
    "caps1_n_dims = 2 \n",
    "\n",
    "conv1_params = {\n",
    "    \"filters\": 64,\n",
    "    \"kernel_size\": 3,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "conv2_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims,\n",
    "    \"kernel_size\": 3,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "\n",
    "conv1 = tf.compat.v1.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
    "conv2 = tf.compat.v1.layers.conv2d(conv1, name=\"conv2\", **conv2_params)\n",
    "\n",
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    #with tf.name_scope(name, default_name=\"squash\"):\n",
    "    with tf.name_scope(name):\n",
    "        #squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "        #                             keep_dims=True)\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keepdims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector\n",
    "    \n",
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")\n",
    "\n",
    "caps2_n_caps = 2 #ini kuubah\n",
    "caps2_n_dims = 16\n",
    "\n",
    "init_sigma = 0.1\n",
    "\n",
    "#W_init = tf.random_normal(\n",
    "W_init = tf.random.normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")\n",
    "\n",
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\") #1\n",
    "\n",
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\") #1\n",
    "\n",
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")\n",
    "\n",
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                       dtype=np.float32, name=\"raw_weights\")\n",
    "\n",
    "routing_weights = tf.nn.softmax(raw_weights, name=\"routing_weights\")\n",
    "\n",
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                   name=\"weighted_predictions\")\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keepdims=True,\n",
    "                             name=\"weighted_sum\")\n",
    "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                              name=\"caps2_output_round_1\")\n",
    "\n",
    "caps2_output_round_1_tiled = tf.tile(\n",
    "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_1_tiled\")\n",
    "\n",
    "agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                      transpose_a=True, name=\"agreement\")\n",
    "\n",
    "raw_weights_round_2 = tf.add(raw_weights, agreement,\n",
    "                             name=\"raw_weights_round_2\")\n",
    "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                        name=\"routing_weights_round_2\")\n",
    "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_2\")\n",
    "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                     axis=1, keepdims=True,\n",
    "                                     name=\"weighted_sum_round_2\")\n",
    "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_2\")\n",
    "\n",
    "caps2_output = caps2_output_round_2\n",
    "\n",
    "def condition(input, counter):\n",
    "    return tf.less(counter, 100) #100\n",
    "\n",
    "def loop_body(input, counter):\n",
    "    output = tf.add(input, tf.square(counter))\n",
    "    return output, tf.add(counter, 1)\n",
    "\n",
    "with tf.name_scope(\"compute_sum_of_squares\"):\n",
    "    counter = tf.constant(1)\n",
    "    sum_of_squares = tf.constant(0)\n",
    "\n",
    "    result = tf.while_loop(condition, loop_body, [sum_of_squares, counter])\n",
    "\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(sess.run(result))\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keepdims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)\n",
    "    \n",
    "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")\n",
    "\n",
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "\n",
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "\n",
    "y = tf.compat.v1.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n",
    "\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5\n",
    "\n",
    "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")\n",
    "\n",
    "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                              name=\"caps2_output_norm\")\n",
    "\n",
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                              name=\"present_error_raw\")\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, 2), #ini kuubah\n",
    "                           name=\"present_error\")\n",
    "\n",
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                             name=\"absent_error_raw\")\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, 2), #ini ku ubah\n",
    "                          name=\"absent_error\")\n",
    "\n",
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "           name=\"L\")\n",
    "\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n",
    "\n",
    "mask_with_labels = tf.compat.v1.placeholder_with_default(False, shape=(),\n",
    "                                               name=\"mask_with_labels\")\n",
    "\n",
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y,        # if True\n",
    "                                 lambda: y_pred,   # if False\n",
    "                                 name=\"reconstruction_targets\")\n",
    "\n",
    "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                 depth=caps2_n_caps,\n",
    "                                 name=\"reconstruction_mask\")\n",
    "\n",
    "reconstruction_mask_reshaped = tf.reshape(\n",
    "    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
    "    name=\"reconstruction_mask_reshaped\")\n",
    "\n",
    "caps2_output_masked = tf.multiply(\n",
    "    caps2_output, reconstruction_mask_reshaped,\n",
    "    name=\"caps2_output_masked\")\n",
    "\n",
    "decoder_input = tf.reshape(caps2_output_masked,\n",
    "                           [-1, caps2_n_caps * caps2_n_dims],\n",
    "                           name=\"decoder_input\")\n",
    "\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = 14 * 14\n",
    "\n",
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.compat.v1.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                                        name=\"hidden1\")\n",
    "    hidden2 = tf.compat.v1.layers.dense(hidden1, n_hidden2,\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        name=\"hidden2\")\n",
    "    decoder_output = tf.compat.v1.layers.dense(hidden2, n_output,\n",
    "                                               activation=tf.nn.sigmoid,\n",
    "                                               name=\"decoder_output\")\n",
    "\n",
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                               name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
    "                                    name=\"reconstruction_loss\")\n",
    "\n",
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")\n",
    "\n",
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_predict_resnetX(filepath):\n",
    "    image = cv2.imread(filepath)\n",
    "    image = preprocess_image(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    features = modelR.predict(image)\n",
    "    combined_feature = np.mean(features, axis=-1, keepdims=True) #1 layer\n",
    "\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        saver.restore(sess, checkpoint_path_R)\n",
    "        caps2_output_value, decoder_output_value, y_pred_value = sess.run(\n",
    "                [caps2_output, decoder_output, y_pred],\n",
    "                feed_dict={X: combined_feature.reshape(1, 14, 14, 1),\n",
    "                        y: np.array([], dtype=np.int64)})\n",
    "\n",
    "# predicted_labels sekarang akan berisi hasil prediksi untuk data X_test\n",
    "    if y_pred_value == 0:\n",
    "        print(\"real\")\n",
    "    else:\n",
    "        print(\"fake\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_predict_resnet(filepath):\n",
    "    image = cv2.imread(filepath)\n",
    "    image = preprocess_image(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    features = modelR.predict(image)\n",
    "    combined_feature = np.mean(features, axis=-1, keepdims=True) #1 layer\n",
    "    \n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        saver = tf.compat.v1.train.import_meta_graph(checkpoint_path_R + '.meta')\n",
    "        saver.restore(sess, checkpoint_path_R)\n",
    "        graph = tf.compat.v1.get_default_graph()\n",
    "        X = graph.get_tensor_by_name(\"X:0\")  # Sesuaikan dengan nama placeholder\n",
    "\n",
    "        # prediksi pada data X_test\n",
    "        predictions = graph.get_tensor_by_name(\"y_pred:0\")  # Ganti nama tensor output \n",
    "        predicted_labels = sess.run(predictions, feed_dict={X: combined_feature.reshape(1, 14, 14, 1)})\n",
    "\n",
    "    # predicted_labels sekarang akan berisi hasil prediksi untuk data X_test\n",
    "    if predicted_labels == 0:\n",
    "        return {\"real\"}\n",
    "    else:\n",
    "        return {\"fake\"}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_predict_vgg(filepath):\n",
    "    image = cv2.imread(filepath)\n",
    "    image = preprocess_image(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = tf.keras.applications.vgg19.preprocess_input(image)\n",
    "    features = modelV.predict(image)\n",
    "    combined_feature = np.mean(features, axis=-1, keepdims=True) #1 layer\n",
    "    \n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        saver = tf.compat.v1.train.import_meta_graph(checkpoint_path_V + '.meta')\n",
    "        saver.restore(sess, checkpoint_path_V)\n",
    "        graph = tf.compat.v1.get_default_graph()\n",
    "        X = graph.get_tensor_by_name(\"X:0\")  # Sesuaikan dengan nama placeholder\n",
    "\n",
    "        # prediksi pada data X_test\n",
    "        predictions = graph.get_tensor_by_name(\"y_pred:0\")  # Ganti nama tensor output \n",
    "        predicted_labels = sess.run(predictions, feed_dict={X: combined_feature.reshape(1, 14, 14, 1)})\n",
    "\n",
    "    # predicted_labels sekarang akan berisi hasil prediksi untuk data X_test\n",
    "    if predicted_labels == 0:\n",
    "        return {\"real\"}\n",
    "    else:\n",
    "        return {\"fake\"}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_predict_xception(filepath):\n",
    "    image = cv2.imread(filepath)\n",
    "    image = preprocess_image(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = tf.keras.applications.xception.preprocess_input(image)\n",
    "    features = modelX.predict(image)\n",
    "    combined_feature = np.mean(features, axis=-1, keepdims=True) #1 layer\n",
    "    \n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        saver = tf.compat.v1.train.import_meta_graph(checkpoint_path_X + '.meta')\n",
    "        saver.restore(sess, checkpoint_path_X)\n",
    "        graph = tf.compat.v1.get_default_graph()\n",
    "        X = graph.get_tensor_by_name(\"X:0\")  # Sesuaikan dengan nama placeholder\n",
    "\n",
    "        # prediksi pada data X_test\n",
    "        predictions = graph.get_tensor_by_name(\"y_pred:0\")  # Ganti nama tensor output \n",
    "        predicted_labels = sess.run(predictions, feed_dict={X: combined_feature.reshape(1, 14, 14, 1)})\n",
    "\n",
    "    # predicted_labels sekarang akan berisi hasil prediksi untuk data X_test\n",
    "    if predicted_labels == 0:\n",
    "        return {\"real\"}\n",
    "    else:\n",
    "        return {\"fake\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_majority_vote(items):\n",
    "    # Count the occurrences of each item in the list\n",
    "    item_counts = Counter(items)\n",
    "\n",
    "    # Find the item with the maximum count\n",
    "    majority_item, majority_count = item_counts.most_common(1)[0]\n",
    "    print(majority_item)\n",
    "\n",
    "    # Check if the majority count is greater than half the length of the list\n",
    "    if majority_count > len(items) / 2:\n",
    "        return str(majority_item)\n",
    "    else:\n",
    "        return \"No majority vote\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(filepath):\n",
    "    hasilV = str(try_predict_vgg(filepath))\n",
    "    hasilR = str(try_predict_resnet(filepath))\n",
    "    hasilX = str(try_predict_xception(filepath))\n",
    "    \n",
    "    items = []\n",
    "    items.append(hasilV)\n",
    "    items.append(hasilR)\n",
    "    items.append(hasilX)\n",
    "\n",
    "    majority_vote = find_majority_vote(items)\n",
    "    print(majority_vote)\n",
    "\n",
    "    if majority_vote == \"{'real'}\":\n",
    "        return {\"result\" : \"real\"}\n",
    "    else:\n",
    "        return {\"result\" : \"deepfake\"}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 192ms/step\n",
      "INFO:tensorflow:Restoring parameters from ./vgg/my_capsule_network\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "INFO:tensorflow:Restoring parameters from ./resnet/my_capsule_network\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "INFO:tensorflow:Restoring parameters from ./xception/my_capsule_network\n",
      "{'real'}\n",
      "{'real'}\n",
      "{'result': 'real'}\n"
     ]
    }
   ],
   "source": [
    "print(voting(\"./public/aadqbokerz.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\SKRIPSI\\be-deepfake\\test.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SKRIPSI/be-deepfake/test.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m try_predict_resnetX\u001b[39m.\u001b[39mpredict(\u001b[39m\"\u001b[39m\u001b[39m./public/aadqbokerz.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "try_predict_resnetX.predict(\"./public/aadqbokerz.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
